{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rizk8UGhAxsZ"
      },
      "outputs": [],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyvi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile demo.py\n",
        "import streamlit as st\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from pyvi import ViTokenizer\n",
        "import torch\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"vinai/bartpho-word\")\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"MinhViet/Bartpho\").to(device)\n",
        "\n",
        "st.markdown(\"\"\"\n",
        "    <style>\n",
        "    .center-text {\n",
        "        text-align: center;\n",
        "    }\n",
        "    </style>\n",
        "    \"\"\", unsafe_allow_html=True)\n",
        "\n",
        "st.markdown(\"<h1 class='center-text'>Abstractive text summarization</h1>\", unsafe_allow_html=True)\n",
        "\n",
        "if 'submitted_question' not in st.session_state:\n",
        "    st.session_state.submitted_question = ''\n",
        "\n",
        "question = st.text_input(\"Nhập văn bản\", st.session_state.submitted_question)\n",
        "segment_question = ViTokenizer.tokenize(question)\n",
        "\n",
        "confirm_button = st.button(\"Xác nhận\")\n",
        "\n",
        "if confirm_button and question:\n",
        "    st.session_state.submitted_question = segment_question\n",
        "\n",
        "if st.session_state.submitted_question:\n",
        "    st.write(\"Đoạn tóm tắt cho văn bản của bạn:\")\n",
        "    encoded_input = tokenizer(st.session_state.submitted_question, return_tensors=\"pt\").to(device)\n",
        "    output = model.generate(input_ids=encoded_input['input_ids'], attention_mask=encoded_input['attention_mask'], max_length=512, num_beams=5)\n",
        "    response = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    clean_response = response.replace('_', ' ')\n",
        "    st.code(clean_response)"
      ],
      "metadata": {
        "id": "NKtgU4VZjNr6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTXcLfdGA0hk"
      },
      "outputs": [],
      "source": [
        "! wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BpVASBrxBNI8"
      },
      "outputs": [],
      "source": [
        "! streamlit run demo.py & npx localtunnel --port 8501"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}